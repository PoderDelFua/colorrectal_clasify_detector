{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNT5-wkYn1zN",
        "outputId": "ce8bc2b8-9253-4e6b-97c5-07c5fd056711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9JnkZ-wlr7G",
        "outputId": "de7e956d-4828-4f46-b008-d967658f93f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Clases de los archivos de 'Serrado' cambiadas a 1 correctamente.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ruta a la carpeta donde est√°n los labels de los serrados\n",
        "carpeta_labels_serrado = '/content/drive/MyDrive/TFG/Anotaciones/Serrados'\n",
        "\n",
        "# Recorremos todos los archivos .txt de esa carpeta\n",
        "for archivo in os.listdir(carpeta_labels_serrado):\n",
        "    if archivo.endswith('.txt'):\n",
        "        ruta = os.path.join(carpeta_labels_serrado, archivo)\n",
        "        nuevas_lineas = []\n",
        "\n",
        "        with open(ruta, 'r') as f:\n",
        "            for linea in f:\n",
        "                partes = linea.strip().split()\n",
        "                if len(partes) > 0:\n",
        "                    partes[0] = '1'  # Reemplazamos la clase 0 por 1, que es la clase de serrado\n",
        "                    nuevas_lineas.append(' '.join(partes))\n",
        "\n",
        "        # Sobrescribimos el archivo con la clase corregida\n",
        "        with open(ruta, 'w') as f:\n",
        "            f.write('\\n'.join(nuevas_lineas))\n",
        "\n",
        "print(\"‚úÖ Clases de los archivos de 'Serrado' cambiadas a 1 correctamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2t6peJnnsku"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "# Rutas de origen\n",
        "NORMAL_IMG = '/content/drive/MyDrive/TFG/colonoscopias/Normal'\n",
        "ADENOMA_IMG = '/content/drive/MyDrive/TFG/colonoscopias/Adenomas'\n",
        "ADENOMA_LBL = '/content/drive/MyDrive/TFG/Anotaciones/Adenomas'\n",
        "SERRADO_IMG = '/content/drive/MyDrive/TFG/colonoscopias/Serrados'\n",
        "SERRADO_LBL = '/content/drive/MyDrive/TFG/Anotaciones/Serrados'\n",
        "\n",
        "# Carpeta final para YOLO (detecci√≥n)\n",
        "DATASET_BASE = '/content/drive/MyDrive/TFG/dataset_deteccion'\n",
        "for split in ['train', 'val', 'test']:\n",
        "    os.makedirs(os.path.join(DATASET_BASE, 'images', split), exist_ok=True)\n",
        "    os.makedirs(os.path.join(DATASET_BASE, 'labels', split), exist_ok=True)\n",
        "\n",
        "# Ratios de divisi√≥n\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSqktJb3pTbC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Funci√≥n para renombrar extensiones .JPG a .jpg\n",
        "def rename_jpg(dir_path):\n",
        "    for f in os.listdir(dir_path):\n",
        "        old_path = os.path.join(dir_path, f)\n",
        "        if not os.path.isfile(old_path):\n",
        "            continue\n",
        "        name, ext = os.path.splitext(f)\n",
        "        ext_lower = ext.lower()\n",
        "        if ext != ext_lower:\n",
        "            new_name = name + ext_lower\n",
        "            new_path = os.path.join(dir_path, new_name)\n",
        "            os.rename(old_path, new_path)\n",
        "\n",
        "# Renombrar im√°genes en todas las carpetas\n",
        "rename_jpg(NORMAL_IMG)\n",
        "rename_jpg(ADENOMA_IMG)\n",
        "rename_jpg(SERRADO_IMG)\n",
        "\n",
        "# Funci√≥n para listar im√°genes y etiquetas\n",
        "def list_imgs_and_labels(img_dir, lbl_dir=None, class_id=None):\n",
        "    img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    data_list = []\n",
        "\n",
        "    for img in img_files:\n",
        "        base = os.path.splitext(img)[0]\n",
        "        img_path = os.path.join(img_dir, img)\n",
        "        lbl_path = os.path.join(lbl_dir, base + '.txt') if lbl_dir else None\n",
        "\n",
        "        if lbl_dir and not os.path.exists(lbl_path):\n",
        "            continue  # Omitir im√°genes de Adenomas y Serrados sin etiquetas\n",
        "\n",
        "        if lbl_dir:\n",
        "            data_list.append((img_path, lbl_path))\n",
        "        else:\n",
        "            # Para im√°genes \"Normal\", creamos un txt vac√≠o\n",
        "            data_list.append((img_path, None))\n",
        "\n",
        "    return data_list\n",
        "\n",
        "# Listar im√°genes y etiquetas\n",
        "norm_data = list_imgs_and_labels(NORMAL_IMG)  # Sin etiquetas\n",
        "ade_data = list_imgs_and_labels(ADENOMA_IMG, ADENOMA_LBL)\n",
        "ser_data = list_imgs_and_labels(SERRADO_IMG, SERRADO_LBL)\n",
        "\n",
        "random.shuffle(norm_data)\n",
        "random.shuffle(ade_data)\n",
        "random.shuffle(ser_data)\n",
        "\n",
        "# Funci√≥n para dividir los datos\n",
        "def split_data(data_list, tr_ratio, val_ratio):\n",
        "    n_total = len(data_list)\n",
        "    n_train = int(n_total * tr_ratio)\n",
        "    n_val = int(n_total * val_ratio)\n",
        "    n_test = n_total - n_train - n_val\n",
        "    return data_list[:n_train], data_list[n_train:n_train + n_val], data_list[n_train + n_val:]\n",
        "\n",
        "# Dividir los datos en train/val/test\n",
        "norm_tr, norm_val, norm_test = split_data(norm_data, train_ratio, val_ratio)\n",
        "ade_tr, ade_val, ade_test = split_data(ade_data, train_ratio, val_ratio)\n",
        "ser_tr, ser_val, ser_test = split_data(ser_data, train_ratio, val_ratio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XxSpM-oTD__",
        "outputId": "95dc3d92-1cd7-4cfe-b531-5bc7efae9900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-98d7791bb66e>:44: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n"
          ]
        }
      ],
      "source": [
        "import albumentations as A\n",
        "\n",
        "# Definici√≥n del pipeline completo de Data Augmentation\n",
        "augment_transform = A.Compose(\n",
        "    [\n",
        "        # Aplica un volteo horizontal aleatorio con probabilidad del 50%\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "\n",
        "        # Ajusta aleatoriamente el brillo y el contraste (¬±20%), con probabilidad 50%\n",
        "        A.RandomBrightnessContrast(\n",
        "            brightness_limit=0.2,\n",
        "            contrast_limit=0.2,\n",
        "            p=0.5\n",
        "        ),\n",
        "\n",
        "        # Rota la imagen aleatoriamente en un rango de -15 a +15 grados, con probabilidad 50%\n",
        "        A.Rotate(limit=15, p=0.5),\n",
        "\n",
        "        # Modifica ligeramente el tono (hue), saturaci√≥n y valor (brillo) de colores con una probabilidad de 30%\n",
        "        A.HueSaturationValue(\n",
        "            hue_shift_limit=20,   # Variaci√≥n m√°xima en el tono (color)\n",
        "            sat_shift_limit=30,   # Variaci√≥n m√°xima en saturaci√≥n (intensidad de color)\n",
        "            val_shift_limit=20,   # Variaci√≥n m√°xima en valor (brillo)\n",
        "            p=0.3\n",
        "        ),\n",
        "\n",
        "        # Aplica traslaciones, escalados o rotaciones ligeras adicionales con probabilidad 50%\n",
        "        A.ShiftScaleRotate(\n",
        "            shift_limit=0.1,      # Traslada imagen hasta ¬±10% en ambas direcciones (x, y)\n",
        "            scale_limit=0.1,      # Escala la imagen hasta ¬±10% (m√°s peque√±a o m√°s grande)\n",
        "            rotate_limit=0,       # No rota m√°s aqu√≠ porque ya est√° en Rotate arriba\n",
        "            border_mode=0,        # Rellena bordes nuevos con negro (valor 0)\n",
        "            p=0.5\n",
        "        ),\n",
        "\n",
        "        # Aplica distorsi√≥n (cizallamiento) horizontal o vertical hasta ¬±10 grados, con probabilidad 30%\n",
        "        A.Affine(\n",
        "            shear=(-10, 10),\n",
        "            p=0.3\n",
        "        ),\n",
        "\n",
        "        # Elimina aleatoriamente peque√±as regiones rectangulares (dropout),\n",
        "        # generando robustez ante posibles oclusiones, con probabilidad 20%\n",
        "        A.CoarseDropout(\n",
        "            max_holes=4,          # Hasta 4 regiones pueden ser eliminadas\n",
        "            max_height=16,        # Altura m√°xima de cada regi√≥n eliminada\n",
        "            max_width=16,         # Ancho m√°ximo de cada regi√≥n eliminada\n",
        "            fill_value=0,         # Valor con el que se rellenan las regiones eliminadas (negro)\n",
        "            p=0.2\n",
        "        ),\n",
        "\n",
        "        # Nota importante:\n",
        "        # Mosaic Augmentation NO se puede realizar directamente con Albumentations.\n",
        "        # En YOLOv8 (Ultralytics) se configura directamente desde los par√°metros de entrenamiento.\n",
        "    ],\n",
        "\n",
        "    # El siguiente bloque es para asegurar que las bounding boxes\n",
        "    # (regiones etiquetadas como p√≥lipos) tambi√©n sean transformadas\n",
        "    # adecuadamente junto con cada imagen.\n",
        "    bbox_params=A.BboxParams(format='yolo', label_fields=['labels'], min_area=1, min_visibility=0.1)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIBvMWaMpQmx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "def copy_and_augment(data_list, subset, class_id=None):\n",
        "    img_dst = os.path.join(DATASET_BASE, 'images', subset)\n",
        "    lbl_dst = os.path.join(DATASET_BASE, 'labels', subset)\n",
        "\n",
        "    os.makedirs(img_dst, exist_ok=True)\n",
        "    os.makedirs(lbl_dst, exist_ok=True)\n",
        "\n",
        "    n_aug = 3 if subset == 'train' else 1  # 3 aumentos solo para train\n",
        "\n",
        "    for img_path, lbl_path in data_list:\n",
        "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "        # Copiar imagen original\n",
        "        new_img_path = os.path.join(img_dst, base + '.jpg')\n",
        "        shutil.copy2(img_path, new_img_path)\n",
        "\n",
        "        if lbl_path:\n",
        "            # Copiar etiquetas existentes\n",
        "            new_lbl_path = os.path.join(lbl_dst, base + '.txt')\n",
        "            shutil.copy2(lbl_path, new_lbl_path)\n",
        "        else:\n",
        "            # Crear etiqueta vac√≠a para im√°genes \"Normal\"\n",
        "            new_lbl_path = os.path.join(lbl_dst, base + '.txt')\n",
        "            open(new_lbl_path, 'w').close()\n",
        "\n",
        "        # Augment solo en train y solo para Adenoma/Serrado (con labels)\n",
        "        if subset != 'train' or lbl_path is None:\n",
        "            continue\n",
        "\n",
        "        img_bgr = cv2.imread(img_path)\n",
        "        if img_bgr is None:\n",
        "            continue\n",
        "\n",
        "        h, w = img_bgr.shape[:2]\n",
        "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Leer bboxes directamente en YOLO (no convertir manualmente a p√≠xeles)\n",
        "        bboxes_list = []\n",
        "        labels_list = []\n",
        "        with open(lbl_path, 'r') as f_lbl:\n",
        "            for line in f_lbl:\n",
        "                parts = line.strip().split()\n",
        "                cls_id = int(parts[0])\n",
        "                x_center, y_center, width, height = map(float, parts[1:])\n",
        "                bboxes_list.append([x_center, y_center, width, height])  # YOLO normalizado directo\n",
        "                labels_list.append(cls_id)\n",
        "\n",
        "        # Generar im√°genes aumentadas usando Albumentations directamente\n",
        "        for i in range(n_aug):\n",
        "            aug_result = augment_transform(image=img_rgb, bboxes=bboxes_list, labels=labels_list)\n",
        "            aug_img = cv2.cvtColor(aug_result['image'], cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            aug_img_path = os.path.join(img_dst, f\"{base}_aug{i}.jpg\")\n",
        "            cv2.imwrite(aug_img_path, aug_img)\n",
        "\n",
        "            aug_lbl_path = os.path.join(lbl_dst, f\"{base}_aug{i}.txt\")\n",
        "\n",
        "            # Guardar etiquetas transformadas directamente\n",
        "            with open(aug_lbl_path, 'w') as f_out:\n",
        "                for bbox, cls_id in zip(aug_result['bboxes'], aug_result['labels']):\n",
        "                    x_center, y_center, width, height = bbox  # Ya formato YOLO normalizado\n",
        "                    f_out.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrKD_t4VpRr9",
        "outputId": "0aa4395f-83f4-4ddc-82ea-359e0e2f1dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéâ Dataset completado.\n"
          ]
        }
      ],
      "source": [
        "# 4. Copiar y augmentar para Adenoma y Serrado\n",
        "\n",
        "copy_and_augment(norm_tr, 'train')\n",
        "copy_and_augment(ade_tr, 'train', 1)\n",
        "copy_and_augment(ser_tr, 'train', 2)\n",
        "\n",
        "print(\"\\nüéâ Dataset completado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxfjLPnGp-VD"
      },
      "outputs": [],
      "source": [
        "# Copiar expl√≠citamente archivos para validaci√≥n (val), sin aumentaci√≥n\n",
        "copy_and_augment(norm_val, 'val')\n",
        "copy_and_augment(ade_val, 'val', 1)\n",
        "copy_and_augment(ser_val, 'val', 2)\n",
        "\n",
        "# Copiar expl√≠citamente archivos para test, sin aumentaci√≥n\n",
        "copy_and_augment(norm_test, 'test')\n",
        "copy_and_augment(ade_test, 'test', 1)\n",
        "copy_and_augment(ser_test, 'test', 2)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
